{"cells":[{"cell_type":"markdown","metadata":{"id":"epei1yI8MCFg"},"source":["## Connect with the GoogleDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLiAddaSRQPX"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"p3xyMrEeMIn6"},"source":["## Import all the modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUV5Fea3J_bc"},"outputs":[],"source":["import os\n","import glob\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","import tensorflow.keras as keras\n","import tensorflow.keras.optimizers as optimizers\n","from sklearn.utils import shuffle\n","import librosa"]},{"cell_type":"markdown","metadata":{"id":"ueiJr7gkMLvd"},"source":["# Load training HW data and assign labels for each data sample (`[1]`)"]},{"cell_type":"code","source":["audio_dir = r'/content/drive/MyDrive/project_updated/Training_Audio_Files/HW'\n","\n","training_images_HW = []\n","training_images_HW_dB = []\n","count = 0\n","\n","for audio_file in os.listdir(audio_dir):\n","    count = count + 1\n","    print(f\"The data sample {audio_file} is processed: {count}/{len(os.listdir(audio_dir))}\")\n","    audio_path = os.path.join(audio_dir, audio_file)\n","    audio, sr = librosa.load(audio_path, sr=6000)\n","\n","    # Mel\n","    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=2048, hop_length=512, win_length=2048, n_mels=64, power=1, center=False) # I think he was using 128 as default\n","    S_dB = 20 * np.log10(spectrogram + 1e-6)\n","    training_images_HW_dB.append(S_dB)\n","    mel_pcen = librosa.pcen(spectrogram*(2**31), sr=sr, hop_length=512, gain=9.99686079e-01, bias=3.17143741e+00, power=3.22058271e-01, time_constant=2.51005792e-03, eps=5.09658383e-07, max_size=1)\n","\n","    training_images_HW.append(mel_pcen)\n","\n","#training_images_HW = np.asarray(training_images_HW_dB)\n","training_images_HW = np.asarray(training_images_HW)\n","training_labels_HW = np.ones(training_images_HW.shape[0])"],"metadata":{"id":"1-vEb3WCXKmT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VlSoCBk4Mat8"},"source":["# Load training NoHW data and assign labels for each data sample (`[0]`)"]},{"cell_type":"code","source":["audio_dir = r'/content/drive/MyDrive/project_updated/Training_Audio_Files/NoHW'\n","\n","training_images_NoHW = []\n","training_images_NoHW_dB = []\n","count = 0\n","\n","for audio_file in os.listdir(audio_dir):\n","    count = count + 1\n","    print(f\"The data sample {audio_file} is processed: {count}/{len(os.listdir(audio_dir))}\")\n","    audio_path = os.path.join(audio_dir, audio_file)\n","    audio, sr = librosa.load(audio_path, sr=6000)\n","\n","    # Mel\n","    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=2048, hop_length=512, win_length=2048, n_mels=64, power=1, center=False) # I think he was using 128 as default\n","    S_dB = 20 * np.log10(spectrogram + 1e-6)\n","    training_images_NoHW_dB.append(S_dB)\n","    mel_pcen = librosa.pcen(spectrogram*(2**31), sr=sr, hop_length=512, gain=9.99686079e-01, bias=3.17143741e+00, power=3.22058271e-01, time_constant=2.51005792e-03, eps=5.09658383e-07, max_size=1)\n","\n","    training_images_NoHW.append(mel_pcen)\n","\n","#training_images_NoHW = np.asarray(training_images_NoHW_dB)\n","training_images_NoHW = np.asarray(training_images_NoHW)\n","training_labels_NoHW = np.zeros(training_images_NoHW.shape[0])"],"metadata":{"id":"T69mTXJJXLIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1BNVKk1R41B"},"outputs":[],"source":["training_data = np.concatenate((training_images_HW, training_images_NoHW), axis=0)\n","training_labels = np.concatenate((training_labels_HW, training_labels_NoHW), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ti9Wc_n2TlhY"},"outputs":[],"source":["training_data, training_labels = shuffle(training_data, training_labels, random_state=42)"]},{"cell_type":"code","source":["training_data = (training_data-np.mean(training_data))/(np.std(training_data))"],"metadata":{"id":"0XCuavLmvmiw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9eKPShmVFlb"},"outputs":[],"source":["import gc\n","gc.collect()\n","del audio, mel_pcen, spectrogram, training_images_HW, training_images_NoHW, training_labels_HW, training_labels_NoHW\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"HE1QGQqiVme-"},"outputs":[],"source":["plt.figure()\n","plt.imshow(np.flipud(training_data[9]), cmap='gray')\n","plt.title(f'Label {training_labels[9]}')\n","plt.show()"]},{"cell_type":"code","source":["plt.figure()\n","plt.hist(np.reshape(training_data, -1), 100)\n","plt.show()"],"metadata":{"id":"yQO3RfnHhdlY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehwU-V6aMd7A"},"source":["# Load validation HW data and assign labels for each data sample (`[1]`)"]},{"cell_type":"code","source":["audio_dir = r'/content/drive/MyDrive/project_updated/Validation_Audio_Files/HW'\n","\n","validation_images_HW = []\n","validation_images_HW_dB = []\n","count = 0\n","\n","for audio_file in os.listdir(audio_dir):\n","    count = count + 1\n","    print(f\"The data sample {audio_file} is processed: {count}/{len(os.listdir(audio_dir))}\")\n","    audio_path = os.path.join(audio_dir, audio_file)\n","    audio, sr = librosa.load(audio_path, sr=6000)\n","\n","    # Mel\n","    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=2048, hop_length=512, win_length=2048, n_mels=64, power=1, center=False) # I think he was using 128 as default\n","    S_dB = 20 * np.log10(spectrogram + 1e-6)\n","    validation_images_HW_dB.append(S_dB)\n","    mel_pcen = librosa.pcen(spectrogram*(2**31), sr=sr, hop_length=512, gain=9.99686079e-01, bias=3.17143741e+00, power=3.22058271e-01, time_constant=2.51005792e-03, eps=5.09658383e-07, max_size=1)\n","\n","    validation_images_HW.append(mel_pcen)\n","\n","#validation_images_HW = np.asarray(validation_images_HW_dB)\n","validation_images_HW = np.asarray(validation_images_HW)\n","validation_labels_HW = np.ones(validation_images_HW.shape[0])"],"metadata":{"id":"UpcKtQ7YaH4u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3bflWphHMgLV"},"source":["# Load validation NoHW data and assign labels for each data sample (`[0]`)"]},{"cell_type":"code","source":["audio_dir = r'/content/drive/MyDrive/project/Validation_Audio_Files/NoHW'\n","validation_images_NoHW =[]\n","validation_images_NoHW_dB = []\n","count = 0\n","\n","for audio_file in os.listdir(audio_dir):\n","    count = count + 1\n","    print(f\"The data sample {audio_file} is processed: {count}/{len(os.listdir(audio_dir))}\")\n","    audio_path = os.path.join(audio_dir, audio_file)\n","    audio, sr = librosa.load(audio_path, sr=6000)\n","\n","    # Mel\n","    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=2048, hop_length=512, win_length=2048, n_mels=64, power=1, center=False) # I think he was using 128 as default\n","    S_dB = 20 * np.log10(spectrogram + 1e-6)\n","    validation_images_NoHW_dB.append(S_dB)\n","    mel_pcen = librosa.pcen(spectrogram*(2**31), sr=sr, hop_length=512, gain=9.99686079e-01, bias=3.17143741e+00, power=3.22058271e-01, time_constant=2.51005792e-03, eps=5.09658383e-07, max_size=1)\n","\n","    validation_images_NoHW.append(mel_pcen)\n","\n","#validation_images_NoHW = np.asarray(validation_images_NoHW_dB)\n","validation_images_NoHW = np.asarray(validation_images_NoHW)\n","validation_labels_NoHW = np.zeros(validation_images_NoHW.shape[0])"],"metadata":{"id":"hZ__A1nKeVk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8aJNoRr3aWSm"},"outputs":[],"source":["validation_data = np.concatenate((validation_images_HW, validation_images_NoHW), axis=0)\n","validation_labels = np.concatenate((validation_labels_HW, validation_labels_NoHW), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QsdKEiuhbA-6"},"outputs":[],"source":["validation_data, validation_labels = shuffle(validation_data, validation_labels, random_state=42)"]},{"cell_type":"code","source":["validation_data = (validation_data-np.mean(validation_data))/(np.std(validation_data))"],"metadata":{"id":"zzRpXOfav_cF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWw3M0uAauIX"},"outputs":[],"source":["import gc\n","gc.collect()\n","del audio, mel_pcen, spectrogram, validation_images_HW, validation_labels_HW, validation_images_NoHW, validation_labels_NoHW\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6QaTFJmbG1c"},"outputs":[],"source":["plt.figure()\n","plt.imshow(np.flipud(validation_data[9]), cmap='gray')\n","plt.title(f'Label {validation_labels[9]}')\n","plt.show()"]},{"cell_type":"code","source":["plt.figure()\n","plt.hist(np.reshape(validation_data, -1), 100)\n","plt.show()"],"metadata":{"id":"F5JyDC7exp9d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p4_jcRNKbjqN"},"source":["## CNN Model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"vX1hTC1abXjM"},"outputs":[],"source":["def model_scratch(input_shape=(64, 231, 1)):\n","\n","  ########################## CNN model (Functional API)###############################\n","  ################################ Model Input #######################################\n","  model_input = keras.Input(shape=input_shape, name='model_input')\n","  ####################################################################################\n","  ####################################################################################\n","  ########################### First 2D Convolutional Layer ###########################\n","  model_conv_1 = keras.layers.Conv2D(filters= 32,\n","                                    kernel_size = (3,3),\n","                                    strides = (2,2),\n","                                    activation='relu',\n","                                    padding='valid',\n","                                    name = 'conv_layer_1'\n","                                    )(model_input)\n","  ####################################################################################\n","  ####################################################################################\n","  ########################## Second 2D Convolutional Layer ###########################\n","  model_conv_2 = keras.layers.Conv2D(64,\n","                                    kernel_size = (3,3),\n","                                    strides = (2,2),\n","                                    activation='relu',\n","                                    padding='valid',\n","                                    name = 'conv_layer_2'\n","                                    )(model_conv_1)\n","  batch_1 = keras.layers.BatchNormalization(name='bn_1')(model_conv_2)\n","  dropout_1 = keras.layers.Dropout(0.2, name='dropout1')(batch_1)\n","  ####################################################################################\n","  ####################################################################################\n","  ########################## Third 2D Convolutional Layer ############################\n","  model_conv_3 = keras.layers.Conv2D(128,\n","                                    kernel_size = (3,3),\n","                                    strides = (1,1),\n","                                    activation='relu',\n","                                    padding='valid',\n","                                    name = 'conv_layer_3'\n","                                    )(dropout_1)\n","  ####################################################################################\n","  ####################################################################################\n","  ########################## Fourth 2D Convolutional Layer ###########################\n","  model_conv_4 = keras.layers.Conv2D(128,\n","                                    kernel_size = (3,3),\n","                                    strides = (2,2),\n","                                    activation='relu',\n","                                    padding='valid',\n","                                    name = 'conv_layer_4'\n","                                    )(model_conv_3)\n","  batch_2 = keras.layers.BatchNormalization(name='bn_2')(model_conv_4)\n","  dropout_2 = keras.layers.Dropout(0.3, name='dropout2')(batch_2)\n","  ####################################################################################\n","  ####################################################################################\n","  ########################### Fifth 2D Convolutional Layer ###########################\n","  model_conv_5 = keras.layers.Conv2D(128,\n","                                    kernel_size = (3,3),\n","                                    strides = (1,1),\n","                                    activation='relu',\n","                                    padding='valid',\n","                                    name = 'conv_layer_5'\n","                                    )(dropout_2)\n","  ####################################################################################\n","  ####################################################################################\n","  ########################### Sixth 2D Convolutional Layer ###########################\n","  model_conv_6 = keras.layers.Conv2D(64,\n","                                    kernel_size = (3,3),\n","                                    strides = (2,2),\n","                                    activation='relu',\n","                                    padding='valid',\n","                                    name = 'conv_layer_6'\n","                                    )(model_conv_5)\n","  batch_3 = keras.layers.BatchNormalization(name='bn_3')(model_conv_6)\n","  ####################################################################################\n","  ####################################################################################\n","  ############################## Global Average Pooling ##############################\n","  gb_lay = keras.layers.GlobalAveragePooling2D(name='glob_av_pool')(batch_3)\n","  ####################################################################################\n","  ####################################################################################\n","  ############################ First Fully Connected Layer ###########################\n","  FC_1 = keras.layers.Dense(256,\n","                            activation='relu',\n","                            use_bias=True,\n","                            kernel_initializer='glorot_uniform',\n","                            bias_initializer='zeros',\n","                            name='FC1')(gb_lay)\n","  dropout_3 = keras.layers.Dropout(0.5, name='dropout3')(FC_1)\n","  ####################################################################################\n","  ####################################################################################\n","  ########################### Second Fully Connected Layer ###########################\n","  FC_2 = keras.layers.Dense(128,\n","                            activation='relu',\n","                            use_bias=True,\n","                            kernel_initializer='glorot_uniform',\n","                            bias_initializer='zeros',\n","                            name='FC2')(dropout_3)\n","  dropout_4 = keras.layers.Dropout(0.2, name='dropout4')(FC_2)\n","  ####################################################################################\n","  ####################################################################################\n","  ################################### Output Layer ###################################\n","  output_layer = keras.layers.Dense(1, activation='sigmoid')(dropout_4)\n","  ####################################################################################\n","  ####################################################################################\n","  ####################################### Model ######################################\n","  model_scratch = keras.models.Model(inputs=model_input, outputs=output_layer)\n","  return model_scratch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36nJlJBXuU9Y"},"outputs":[],"source":["model = model_scratch(input_shape=(64, 231, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyVKicWZughl"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"lxbBXljab6VC"},"source":["## Compile the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMvKRTd2by4M"},"outputs":[],"source":["def compiling(model,\n","              optimizer='adam',\n","              learning_rate=0.001,\n","              decaying=True):\n","\n","    if decaying==True:\n","        initial_learning_rate = learning_rate\n","        lr_schedule = optimizers.schedules.ExponentialDecay(initial_learning_rate,\n","                                                                   decay_steps=90,\n","                                                                  decay_rate=0.75,\n","                                                                  staircase=True)\n","\n","        if optimizer=='adam':\n","            optimizer = optimizers.Adam(learning_rate=lr_schedule)\n","        elif optimizer=='adagrad':\n","            optimizer = optimizers.Adagrad(learning_rate=lr_schedule)\n","        elif optimizer=='rmsprop':\n","            optimizer = optimizers.RMSprop(learning_rate=lr_schedule)\n","        elif optimizer=='adamax':\n","            optimizer = optimizers.Adamax(learning_rate=lr_schedule)\n","        else:\n","            raise ValueError(\"Please enter a valid optimizer\")\n","        loss_fn = keras.losses.BinaryCrossentropy()\n","        model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n","    else:\n","        if optimizer=='adam':\n","            optimizer = optimizers.Adam(learning_rate=learning_rate)\n","        elif optimizer=='adagrad':\n","            optimizer = optimizers.Adagrad(learning_rate=learning_rate)\n","        elif optimizer=='rmsprop':\n","            optimizer = optimizers.RMSprop(learning_rate=learning_rate)\n","        elif optimizer=='adamax':\n","            optimizer = optimizers.Adamax(learning_rate=learning_rate)\n","        else:\n","            raise ValueError(\"Please enter a valid optimizer\")\n","\n","        loss_fn = keras.losses.BinaryCrossentropy()\n","        model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x79MXOF6xXg6"},"outputs":[],"source":["compiling(model, optimizer='adam', learning_rate=0.001, decaying=True)"]},{"cell_type":"markdown","metadata":{"id":"EZUXg89ucaZL"},"source":["## Train the Model"]},{"cell_type":"code","source":["training_data = training_data[:,:,:,np.newaxis]\n","validation_data = validation_data[:,:,:,np.newaxis]"],"metadata":{"id":"UPg5v_63k1Db"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmrDV9CGvOHc"},"outputs":[],"source":["history = model.fit(training_data, training_labels, batch_size=32, epochs=100, validation_data=(validation_data, validation_labels), verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"XYt_muVFAA9D"},"source":["# Save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9sRX-vydBJa"},"outputs":[],"source":["from tensorflow.keras.models import model_from_json\n","# Save model after training finished (see for more details,\n","# see: https://github.com/aaolcay/save_load_NN_model)\n","# serialize model to JSON\n","model_json = model.to_json()\n","with open(\"/content/drive/MyDrive/project_updated/model.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"/content/drive/MyDrive/project_updated/model.weights.h5\")\n","print(\"Saved model to disk\")"]},{"cell_type":"markdown","metadata":{"id":"PufYu4vJAHzo"},"source":["# Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63RSfmBj8TRX"},"outputs":[],"source":["json_file = open('/content/drive/MyDrive/project_updated/model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"/content/drive/MyDrive/project_updated/model.weights.h5\")\n","print(\"Loaded model from disk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCa_cK1J-Nsq"},"outputs":[],"source":["predicted_labels = loaded_model.predict(validation_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOyLVLGU-fk9"},"outputs":[],"source":["predicted_labels[predicted_labels>=0.5] = 1\n","predicted_labels[predicted_labels<0.5] = 0\n","predicted_labels = predicted_labels[:,0]\n","a = predicted_labels==validation_labels\n","len(np.where(a==True)[0])/validation_labels.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMFaAyarB8bf"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}